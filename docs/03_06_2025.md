# Thursday 3-06-2025

## Hands On RTOS with Microcontrollers

### Chapter 3: Task Signaling and Communication Mechanisms  

#### RTOS Queues
Used for task-task comms
Task can put and receive item from queue
Queues are FIFO by default
If a queue is full when a task tries to insert it will wait for a predetermined amount of time. If this timeout is reached the send will fail. The task can do nothing or something when the failure happens
When a task tries to receive from an empty queue it will wait for a predetermined amount of time. If this timeout expires the receive will fail.

#### RTOS Semaphores 
Similar to a flag
An ISR has finished, can give a semaphore 
Can be used to synchronize tasks
Can be used to restrict the number of users of a resource

##### Counting semaphores
Usually used to manage access to shared resources 
Can be configured to hold a maximum value called the ceiling. Think limited number of socket connections

##### Binary semaphores
Much like a flag, counting semaphore with ceiling of 1

#### RTOS Mutexes (mutual exclusion)

##### Priority Inversion
A higher priority task ends up waiting on lower priority tasks

Priority inheritance: mutexes have the ability to temporarily change the priority of a task to avoid causing major delays.
So if a lower priority task is holding the mutex but a higher priority task is waiting, the scheduler will temporarily raise the priority of the lower priority task until it releases the mutex.

### The Design of a Practical System for Fault-Tolerant Virtual Machines

 A common approach to implementing fault tolerance to implementing fault tolerance is the primary/backup approach where a backup server is always able to take over if the primary server fails. The state of the server must be kept nearly identical to the primary server at all times. 
 The bandwidth needed to send the state, particularly changes in memory is very large
 Another approach is the state machine approach where given the same starting state the same instructions are executed on both primary and backup. 
 Hypervisor of VMs is able to capture all the inputs and any information relating to non deterministic operations for primary and replay on backup VM
 Low bandwidth of this approach allows for greater physical separation between primary and backup
 Can restore redundancy after a failure by starting a new backup vm of any available server in the cluster

 All input the primary receives is sent to backup over the logging channel
 The system uses a combination of UDP heart beating and observing the logging channel

 #### Deterministic replay: Non deterministic events such as virtual interrupts and non deterministic operations (reading clock cycle counter) affect VM state This presents three challenge for replicating any vm running any os and workload:
 - Correctly capturing all the input and non determinism necessary to ensure deterministic execution of a backup vm
 - correctly applying the inputs and non determinism to the backup vm
 - doing so in a manner that doesn't degrade performance

 deterministic replay records the inputs and all possible non determinism associated with the vm execution in stream of log entries written to a log file. The execution can be exactly replayed by reading the entries in this log file

 Each interrupt is recorded as it occurs amd efficiently delivered at the appropriate instruction while being replayed

#### FT Protocol

Output Requirement: If the backup vm ever takes over after a failure fo the primary the backup vm will continue executing in a way that is entirely consistent with all outputs that the primary vm has sent to the external world

Output Rule: The primary vm may not send an output to the external world, until the backup vm has received and processed the log entry associated with the operation producing the result

The output requirement can be ensured by delaying any external output e.g. a network packet until the backup has acked 

Cannot garuntee all outputs are produced exactly once in a failover situation. Rely on TCP to detect duplicate packets

To avoid split brain problems we make use of the shared storage that stores that stores the stored the virtual disks of the vm. When either a primary or backup vm want to go live it executes an atomic test and set operation on the shared storage. If the operation succeeds the vm is allowed to go live. If the operation fails then the other vm must have already gon live so the current vm halts itself. if the vm cannot access storage with just waits until it can.

